{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for creating information-loss manipulation datasets from the Pereira2018 fMRI stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from os.path import abspath\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import csv\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rdma/vast-rdma/vast/cpl/ckauf/perturbed-neural-nlp/ressources/stimuli_creation\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rdma/vast-rdma/vast/cpl/ckauf/perturbed-neural-nlp\n"
     ]
    }
   ],
   "source": [
    "importpath = abspath('../..')\n",
    "os.chdir(importpath)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add seeds for reproducability\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load base stimulus dataframe (Pereira 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lookup from /om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/brainio_collection/lookup.csv\n",
      "/rdma/vast-rdma/vast/cpl/ckauf/perturbed-neural-nlp/neural_nlp/../ressources/stimuli\n",
      "\n",
      "\n",
      " We're running in the NEW version of the implementations.py script.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>stimulus_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>story</th>\n",
       "      <th>passage_index</th>\n",
       "      <th>passage_label</th>\n",
       "      <th>passage_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beekeeping encourages the conservation of loca...</td>\n",
       "      <td>0</td>\n",
       "      <td>243sentences.0</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is in every beekeeper's interest to conserv...</td>\n",
       "      <td>1</td>\n",
       "      <td>243sentences.1</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a passive form of agriculture, it does not ...</td>\n",
       "      <td>2</td>\n",
       "      <td>243sentences.2</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beekeepers also discourage the use of pesticid...</td>\n",
       "      <td>3</td>\n",
       "      <td>243sentences.3</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artisanal beekeepers go to extremes for their ...</td>\n",
       "      <td>4</td>\n",
       "      <td>243sentences.4</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>2</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Some windows have multiple panes to increase i...</td>\n",
       "      <td>379</td>\n",
       "      <td>384sentences.379</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.building_part</td>\n",
       "      <td>95</td>\n",
       "      <td>Window</td>\n",
       "      <td>building_part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>A woman is a female human adult.</td>\n",
       "      <td>380</td>\n",
       "      <td>384sentences.380</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>A woman is stereotypically seen as a caregiver.</td>\n",
       "      <td>381</td>\n",
       "      <td>384sentences.381</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>A woman can become pregnant and bear children.</td>\n",
       "      <td>382</td>\n",
       "      <td>384sentences.382</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>A woman has different reproductive organs than...</td>\n",
       "      <td>383</td>\n",
       "      <td>384sentences.383</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  sentence_num  \\\n",
       "0    Beekeeping encourages the conservation of loca...             0   \n",
       "1    It is in every beekeeper's interest to conserv...             1   \n",
       "2    As a passive form of agriculture, it does not ...             2   \n",
       "3    Beekeepers also discourage the use of pesticid...             3   \n",
       "4    Artisanal beekeepers go to extremes for their ...             4   \n",
       "..                                                 ...           ...   \n",
       "622  Some windows have multiple panes to increase i...           379   \n",
       "623                   A woman is a female human adult.           380   \n",
       "624    A woman is stereotypically seen as a caregiver.           381   \n",
       "625     A woman can become pregnant and bear children.           382   \n",
       "626  A woman has different reproductive organs than...           383   \n",
       "\n",
       "          stimulus_id    experiment                       story  \\\n",
       "0      243sentences.0  243sentences     243sentences.beekeeping   \n",
       "1      243sentences.1  243sentences     243sentences.beekeeping   \n",
       "2      243sentences.2  243sentences     243sentences.beekeeping   \n",
       "3      243sentences.3  243sentences     243sentences.beekeeping   \n",
       "4      243sentences.4  243sentences     243sentences.beekeeping   \n",
       "..                ...           ...                         ...   \n",
       "622  384sentences.379  384sentences  384sentences.building_part   \n",
       "623  384sentences.380  384sentences          384sentences.human   \n",
       "624  384sentences.381  384sentences          384sentences.human   \n",
       "625  384sentences.382  384sentences          384sentences.human   \n",
       "626  384sentences.383  384sentences          384sentences.human   \n",
       "\n",
       "     passage_index passage_label passage_category  \n",
       "0                1    beekeeping       beekeeping  \n",
       "1                1    beekeeping       beekeeping  \n",
       "2                1    beekeeping       beekeeping  \n",
       "3                1    beekeeping       beekeeping  \n",
       "4                2    beekeeping       beekeeping  \n",
       "..             ...           ...              ...  \n",
       "622             95        Window    building_part  \n",
       "623             96         Woman            human  \n",
       "624             96         Woman            human  \n",
       "625             96         Woman            human  \n",
       "626             96         Woman            human  \n",
       "\n",
       "[627 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neural_nlp.benchmarks.neural import *\n",
    "import neural_nlp\n",
    "from neural_nlp.stimuli import StimulusSet\n",
    "import xarray as xr\n",
    "\n",
    "benchmark_pool = [\n",
    "    # primary benchmarks\n",
    "    ('Pereira2018-encoding', PereiraEncoding),\n",
    "]\n",
    "benchmark_pool = {identifier: LazyLoad(lambda identifier=identifier, ctr=ctr: ctr(identifier=identifier))\n",
    "                  for identifier, ctr in benchmark_pool}\n",
    "\n",
    "# fetch stimulus set\n",
    "benchmark = benchmark_pool['Pereira2018-encoding']\n",
    "stimuli_df = benchmark._target_assembly.attrs['stimulus_set']\n",
    "stimuli_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coordinates:\n",
       "  * presentation      (presentation) MultiIndex\n",
       "  - stimulus_num      (presentation) int64 0 0 1 1 2 2 3 ... 12 12 13 13 14 14\n",
       "  - passage_index     (presentation) int64 1 1 1 1 1 1 1 1 2 ... 3 4 4 4 4 4 4 4\n",
       "  - passage_label     (presentation) object 'Accordion' ... 'dreams'\n",
       "  - passage_category  (presentation) object 'music' 'beekeeping' ... 'dreams'\n",
       "  - stimulus_id       (presentation) object '384sentences.0' ... '243sentences.14'\n",
       "  - story             (presentation) object '384sentences.music' ... '243sentences.dreams'\n",
       "  - experiment        (presentation) object '384sentences' ... '243sentences'\n",
       "  * neuroid           (neuroid) MultiIndex\n",
       "  - subject           (neuroid) object '018' '018' '018' ... '018' '018' '018'\n",
       "  - voxel_num         (neuroid) int64 28 29 31 32 38 42 ... 152 153 154 159 160\n",
       "  - atlas             (neuroid) object 'language' 'language' ... 'language'\n",
       "  - filter_strategy   (neuroid) object '' '' '' '' '' '' ... '' '' '' '' '' ''\n",
       "  - atlas_selection   (neuroid) object 'from90to100prcnt' ... 'from90to100prcnt'\n",
       "  - roi               (neuroid) object 'LH_AntTemp' ... 'LH_AntTemp'\n",
       "  - indices_in_3d     (neuroid) int64 72505 72506 72584 ... 87754 87831 87832\n",
       "  - col_to_coord_1    (neuroid) int64 62 63 62 63 63 63 63 ... 65 62 63 64 62 63\n",
       "  - col_to_coord_2    (neuroid) int64 63 63 64 64 65 66 63 ... 65 66 66 66 67 67\n",
       "  - col_to_coord_3    (neuroid) int64 10 10 10 10 10 10 11 ... 12 12 12 12 12 12\n",
       "  - neuroid_id        (neuroid) object '018.28' '018.29' ... '018.159' '018.160'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark content\n",
    "benchmark._target_assembly.values.shape\n",
    "benchmark._target_assembly.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rdma/vast-rdma/vast/cpl/ckauf/perturbed-neural-nlp/ressources/stimuli_creation\n",
      "/rdma/vast-rdma/vast/cpl/ckauf/perturbed-neural-nlp/ressources/scrambled_stimuli_dfs\n"
     ]
    }
   ],
   "source": [
    "stimuli_path = os.path.join(os.getcwd(),'ressources/stimuli_creation')\n",
    "os.chdir(stimuli_path)\n",
    "print(os.getcwd())\n",
    "\n",
    "savedir = abspath('../scrambled_stimuli_dfs')\n",
    "print(savedir)\n",
    "os.makedirs(savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create different perturbed versions of the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get original dataset in correct formatting. NOTE: \"stim_243sentences_scrambled.txt\" and \"stim_384sentences_scrambled.txt\" are created via running \"get_original_sentenceset.ipynb\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_sentenceset(filename):\n",
    "    with open(os.path.join(stimuli_path,filename),\"r\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        sentences = list(reader)\n",
    "    Original = [sentence[1] + '.' for sentence in sentences if int(sentence[0]) == 0]\n",
    "    \n",
    "    return Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_2433 = get_original_sentenceset(\"stim_243sentences_scrambled.txt\")\n",
    "Original_384 = get_original_sentenceset(\"stim_384sentences_scrambled.txt\")\n",
    "\n",
    "Original = Original_243 + Original_384"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation | O'Connor & Andreas (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beekeeping encourages the conservation of local habitats.', \"it is in every beekeeper's interest to conserve local plants that produce pollen.\", 'as a passive form of agriculture it does not require that native vegetation be cleared to make way for crops.', 'beekeepers also discourage the use of pesticides on crops because they could kill the honeybees.', 'artisanal beekeepers go to extremes for their craft but their product is worth the effort.']\n"
     ]
    }
   ],
   "source": [
    "#This is the list of stimuli we create the perturbations from\n",
    "original_stimuli = Original\n",
    "print(original_stimuli[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/om2/user/ckauf/anaconda/envs/perturbedenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "#Source: https://stackoverflow.com/questions/49271730/how-to-parse-verbs-using-spacy\n",
    "#!pip3 install spacy\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(beekeeping, 'VERB'), (encourages, 'VERB'), (the, 'DET'), (conservation, 'NOUN'), (of, 'ADP'), (local, 'ADJ'), (habitats, 'NOUN'), (., 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(original_stimuli[0])\n",
    "print([(elm, elm.pos_) for elm in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: words do not include dependent parts, like possessive markers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 it is in every beekeeper's interest to conserve local plants that produce pollen.\n",
      "[(it, 'PRON'), (is, 'AUX'), (in, 'ADP'), (every, 'DET'), (beekeeper, 'NOUN'), ('s, 'PART'), (interest, 'NOUN'), (to, 'PART'), (conserve, 'VERB'), (local, 'ADJ'), (plants, 'NOUN'), (that, 'DET'), (produce, 'VERB'), (pollen, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "76 she uses digital animation to help doctors understand structures within a patient's body.\n",
      "[(she, 'PRON'), (uses, 'VERB'), (digital, 'ADJ'), (animation, 'NOUN'), (to, 'PART'), (help, 'VERB'), (doctors, 'NOUN'), (understand, 'VERB'), (structures, 'NOUN'), (within, 'ADP'), (a, 'DET'), (patient, 'NOUN'), ('s, 'PART'), (body, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "115 while the tuxedo is still preferred today's grooms are making personal statements in wedding attire.\n",
      "[(while, 'SCONJ'), (the, 'DET'), (tuxedo, 'NOUN'), (is, 'AUX'), (still, 'ADV'), (preferred, 'VERB'), (today, 'NOUN'), ('s, 'PART'), (grooms, 'NOUN'), (are, 'AUX'), (making, 'VERB'), (personal, 'ADJ'), (statements, 'NOUN'), (in, 'ADP'), (wedding, 'NOUN'), (attire, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "142 families have to adjust to the patient's loss of independence.\n",
      "[(families, 'NOUN'), (have, 'VERB'), (to, 'PART'), (adjust, 'VERB'), (to, 'ADP'), (the, 'DET'), (patient, 'NOUN'), ('s, 'PART'), (loss, 'NOUN'), (of, 'ADP'), (independence, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "147 at the doctor's office afterward the x-ray clearly showed the fracture.\n",
      "[(at, 'ADP'), (the, 'DET'), (doctor, 'NOUN'), ('s, 'PART'), (office, 'NOUN'), (afterward, 'ADV'), (the, 'DET'), (x, 'X'), (-, 'NOUN'), (ray, 'NOUN'), (clearly, 'ADV'), (showed, 'VERB'), (the, 'DET'), (fracture, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "175 most importantly the content of the painting should reveal a glimpse of the painter's soul.\n",
      "[(most, 'ADV'), (importantly, 'ADV'), (the, 'DET'), (content, 'NOUN'), (of, 'ADP'), (the, 'DET'), (painting, 'NOUN'), (should, 'AUX'), (reveal, 'VERB'), (a, 'DET'), (glimpse, 'NOUN'), (of, 'ADP'), (the, 'DET'), (painter, 'NOUN'), ('s, 'PART'), (soul, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "180 an artist's eye is not a camera lens that has to record everything within its field of vision.\n",
      "[(an, 'DET'), (artist, 'NOUN'), ('s, 'PART'), (eye, 'NOUN'), (is, 'AUX'), (not, 'PART'), (a, 'DET'), (camera, 'NOUN'), (lens, 'NOUN'), (that, 'DET'), (has, 'VERB'), (to, 'PART'), (record, 'VERB'), (everything, 'PRON'), (within, 'ADP'), (its, 'PRON'), (field, 'NOUN'), (of, 'ADP'), (vision, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "188 early findings suggest that logging may have facilitated the barred owl's invasion.\n",
      "[(early, 'ADJ'), (findings, 'NOUN'), (suggest, 'VERB'), (that, 'SCONJ'), (logging, 'NOUN'), (may, 'AUX'), (have, 'AUX'), (facilitated, 'VERB'), (the, 'DET'), (barred, 'VERB'), (owl, 'NOUN'), ('s, 'PART'), (invasion, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "199 the seal is an important part of the polar bear's diet.\n",
      "[(the, 'DET'), (seal, 'NOUN'), (is, 'AUX'), (an, 'DET'), (important, 'ADJ'), (part, 'NOUN'), (of, 'ADP'), (the, 'DET'), (polar, 'ADJ'), (bear, 'NOUN'), ('s, 'PART'), (diet, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "200 when hunting they will wait by a seal's breathing hole or stalk seals that are basking on the ice.\n",
      "[(when, 'ADV'), (hunting, 'VERB'), (they, 'PRON'), (will, 'AUX'), (wait, 'VERB'), (by, 'ADP'), (a, 'DET'), (seal, 'NOUN'), ('s, 'PART'), (breathing, 'NOUN'), (hole, 'NOUN'), (or, 'CCONJ'), (stalk, 'NOUN'), (seals, 'NOUN'), (that, 'DET'), (are, 'AUX'), (basking, 'VERB'), (on, 'ADP'), (the, 'DET'), (ice, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "204 a castle could easily control lands within a day's walk.\n",
      "[(a, 'DET'), (castle, 'NOUN'), (could, 'AUX'), (easily, 'ADV'), (control, 'VERB'), (lands, 'NOUN'), (within, 'ADP'), (a, 'DET'), (day, 'NOUN'), ('s, 'PART'), (walk, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "205 during times of attack peasants livestock and property could be brought inside the castle's walls for protection.\n",
      "[(during, 'ADP'), (times, 'NOUN'), (of, 'ADP'), (attack, 'NOUN'), (peasants, 'NOUN'), (livestock, 'NOUN'), (and, 'CCONJ'), (property, 'NOUN'), (could, 'AUX'), (be, 'AUX'), (brought, 'VERB'), (inside, 'ADP'), (the, 'DET'), (castle, 'NOUN'), ('s, 'PART'), (walls, 'NOUN'), (for, 'ADP'), (protection, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "213 this led into the chamber at the pyramid's center.\n",
      "[(this, 'DET'), (led, 'VERB'), (into, 'ADP'), (the, 'DET'), (chamber, 'NOUN'), (at, 'ADP'), (the, 'DET'), (pyramid, 'NOUN'), ('s, 'PART'), (center, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "220 some think ramps were built inside the pyramid's walls to raise stone blocks.\n",
      "[(some, 'DET'), (think, 'NOUN'), (ramps, 'NOUN'), (were, 'AUX'), (built, 'VERB'), (inside, 'ADP'), (the, 'DET'), (pyramid, 'NOUN'), ('s, 'PART'), (walls, 'NOUN'), (to, 'PART'), (raise, 'VERB'), (stone, 'NOUN'), (blocks, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "242 this has led to more injuries particularly to ligaments in the skier's knee.\n",
      "[(this, 'DET'), (has, 'AUX'), (led, 'VERB'), (to, 'ADP'), (more, 'ADJ'), (injuries, 'NOUN'), (particularly, 'ADV'), (to, 'ADP'), (ligaments, 'NOUN'), (in, 'ADP'), (the, 'DET'), (skier, 'NOUN'), ('s, 'PART'), (knee, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "326 coffee is the world's seventh-largest legal agricultural export.\n",
      "[(coffee, 'NOUN'), (is, 'AUX'), (the, 'DET'), (world, 'NOUN'), ('s, 'PART'), (seventh, 'ADJ'), (-, 'PUNCT'), (largest, 'ADJ'), (legal, 'ADJ'), (agricultural, 'ADJ'), (export, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "357 most earthquakes are caused by the release of energy in the earth's crust.\n",
      "[(most, 'ADJ'), (earthquakes, 'NOUN'), (are, 'AUX'), (caused, 'VERB'), (by, 'ADP'), (the, 'DET'), (release, 'NOUN'), (of, 'ADP'), (energy, 'NOUN'), (in, 'ADP'), (the, 'DET'), (earth, 'NOUN'), ('s, 'PART'), (crust, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "545 women's shoes often have high heels and come in many styles and colors.\n",
      "[(women, 'NOUN'), ('s, 'PART'), (shoes, 'NOUN'), (often, 'ADV'), (have, 'VERB'), (high, 'ADJ'), (heels, 'NOUN'), (and, 'CCONJ'), (come, 'VERB'), (in, 'ADP'), (many, 'ADJ'), (styles, 'NOUN'), (and, 'CCONJ'), (colors, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n",
      "575 theft is the taking of person's property without their consent.\n",
      "[(theft, 'NOUN'), (is, 'AUX'), (the, 'DET'), (taking, 'NOUN'), (of, 'ADP'), (person, 'NOUN'), ('s, 'PART'), (property, 'NOUN'), (without, 'ADP'), (their, 'PRON'), (consent, 'NOUN'), (., 'PUNCT')]\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for ind, sent in enumerate(original_stimuli):\n",
    "    printing = False\n",
    "    tokens = nlp(sent)\n",
    "    for elm in tokens:\n",
    "        if elm.pos_ == \"PART\" and str(elm).startswith(\"'\"):\n",
    "            printing = True\n",
    "    if printing is True:\n",
    "        print(ind, sent)\n",
    "        print([(elm, elm.pos_) for elm in tokens])\n",
    "        print(\"*\"* 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perturbed_datasets(sentences,perturb_type):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    * original sentence list (already lower-cased and stripped from punctuation for permute_sentences.py script)\n",
    "    * perturb_type = what should stay in the stimuli file?\n",
    "        nouns: only nouns\n",
    "        nounsverbs: only nouns and verbs\n",
    "        etc\n",
    "    Output:\n",
    "    * list of perturbed sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    n = ['NOUN', 'PROPN', 'PRON'] #same as in O'Connor & Andreas (2021)\n",
    "    v = ['VERB']\n",
    "    a = ['ADJ']\n",
    "    adv = ['ADV']\n",
    "    \n",
    "    if perturb_type == 'nouns':\n",
    "        pos_list = n\n",
    "    elif perturb_type == 'verbs':\n",
    "        pos_list = v\n",
    "    elif perturb_type == 'nounsverbs':\n",
    "        pos_list = n + v\n",
    "    elif perturb_type == 'nounsverbsadj':\n",
    "        pos_list = n + v + a\n",
    "    elif perturb_type == 'contentwords':\n",
    "        pos_list = n + v + a + adv\n",
    "    elif perturb_type == 'functionwords':\n",
    "        pos_list = n + v + a + adv #exclude in next step\n",
    "    else:\n",
    "        print(\"Unknown condition\")\n",
    "        \n",
    "    perturbed_sentences = []\n",
    "    for sent in sentences:\n",
    "        tokens = nlp(sent)\n",
    "        if perturb_type != \"functionwords\": #if some kind of content words\n",
    "            \n",
    "            perturbed_sentences.append(' '.join([str(elm).lower() for elm in tokens if elm.pos_ in pos_list]) + \".\")\n",
    "                \n",
    "        else:\n",
    "            fn_sentence = ' '.join([str(elm).lower() for elm in tokens if elm.pos_ not in pos_list])\n",
    "            fn_sentence = fn_sentence.rstrip(\" .\") + \".\" #add final period without space to avoid it being tokenized as a \"new word\"\n",
    "            perturbed_sentences.append(fn_sentence)\n",
    "            \n",
    "    return perturbed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conservation habitats.',\n",
       " 'it beekeeper interest plants pollen.',\n",
       " 'form agriculture it vegetation way crops.',\n",
       " 'beekeepers use pesticides crops they honeybees.',\n",
       " 'beekeepers extremes their craft their product effort.',\n",
       " 'honey quality character quantity consistency.',\n",
       " 'honey beekeepers micromanagers their honeybees.',\n",
       " 'they fields nectar ways honey.',\n",
       " 'beekeeper hive hum bees air.',\n",
       " 'beekeeper honey stores pollen supplies bee nursery.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_sentences = get_perturbed_datasets(original_stimuli,perturb_type='nouns')\n",
    "noun_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(stimuli_df, original_stimuli, perturb_type):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    * original benchmark dataframe\n",
    "    * original stimuli (list of sentences)\n",
    "    * perturbation type > what should stay in the stimuli?\n",
    "    Output:\n",
    "    * saves perturbed benchmark dataframe to save directory\n",
    "    \"\"\"\n",
    "    perturbed_sentences = get_perturbed_datasets(original_stimuli,perturb_type)\n",
    "    \n",
    "    perturbed_df = stimuli_df.copy()\n",
    "    perturbed_df[\"sentence\"] = perturbed_sentences\n",
    "\n",
    "    else:\n",
    "        fname = f\"{savedir}/stimuli_{perturb_type}.pkl\"\n",
    "    with open(fname, 'wb') as fout:\n",
    "        pickle.dump(perturbed_df, fout)\n",
    "    return perturbed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets (mostly O'Connor & Andreas (2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset for perturbation type: nouns_delete50percent\n",
      "Created dataset for perturbation type: contentwords\n",
      "Created dataset for perturbation type: nouns\n",
      "Created dataset for perturbation type: verbs\n",
      "Created dataset for perturbation type: nounsverbs\n",
      "Created dataset for perturbation type: nounsverbsadj\n",
      "Created dataset for perturbation type: functionwords\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>stimulus_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>story</th>\n",
       "      <th>passage_index</th>\n",
       "      <th>passage_label</th>\n",
       "      <th>passage_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the of.</td>\n",
       "      <td>0</td>\n",
       "      <td>243sentences.0</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is in every 's to that.</td>\n",
       "      <td>1</td>\n",
       "      <td>243sentences.1</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as a of does not that be to for.</td>\n",
       "      <td>2</td>\n",
       "      <td>243sentences.2</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the of on because could the.</td>\n",
       "      <td>3</td>\n",
       "      <td>243sentences.3</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to for but the.</td>\n",
       "      <td>4</td>\n",
       "      <td>243sentences.4</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>2</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>some to.</td>\n",
       "      <td>379</td>\n",
       "      <td>384sentences.379</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.building_part</td>\n",
       "      <td>95</td>\n",
       "      <td>Window</td>\n",
       "      <td>building_part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>a is a.</td>\n",
       "      <td>380</td>\n",
       "      <td>384sentences.380</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>a is as a.</td>\n",
       "      <td>381</td>\n",
       "      <td>384sentences.381</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>a can and.</td>\n",
       "      <td>382</td>\n",
       "      <td>384sentences.382</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>a than a.</td>\n",
       "      <td>383</td>\n",
       "      <td>384sentences.383</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentence  sentence_num       stimulus_id  \\\n",
       "0                             the of.             0    243sentences.0   \n",
       "1             is in every 's to that.             1    243sentences.1   \n",
       "2    as a of does not that be to for.             2    243sentences.2   \n",
       "3        the of on because could the.             3    243sentences.3   \n",
       "4                     to for but the.             4    243sentences.4   \n",
       "..                                ...           ...               ...   \n",
       "622                          some to.           379  384sentences.379   \n",
       "623                           a is a.           380  384sentences.380   \n",
       "624                        a is as a.           381  384sentences.381   \n",
       "625                        a can and.           382  384sentences.382   \n",
       "626                         a than a.           383  384sentences.383   \n",
       "\n",
       "       experiment                       story  passage_index passage_label  \\\n",
       "0    243sentences     243sentences.beekeeping              1    beekeeping   \n",
       "1    243sentences     243sentences.beekeeping              1    beekeeping   \n",
       "2    243sentences     243sentences.beekeeping              1    beekeeping   \n",
       "3    243sentences     243sentences.beekeeping              1    beekeeping   \n",
       "4    243sentences     243sentences.beekeeping              2    beekeeping   \n",
       "..            ...                         ...            ...           ...   \n",
       "622  384sentences  384sentences.building_part             95        Window   \n",
       "623  384sentences          384sentences.human             96         Woman   \n",
       "624  384sentences          384sentences.human             96         Woman   \n",
       "625  384sentences          384sentences.human             96         Woman   \n",
       "626  384sentences          384sentences.human             96         Woman   \n",
       "\n",
       "    passage_category  \n",
       "0         beekeeping  \n",
       "1         beekeeping  \n",
       "2         beekeeping  \n",
       "3         beekeeping  \n",
       "4         beekeeping  \n",
       "..               ...  \n",
       "622    building_part  \n",
       "623            human  \n",
       "624            human  \n",
       "625            human  \n",
       "626            human  \n",
       "\n",
       "[627 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loop over perturbation types to create O'Connor & Andreas (2021) datasets\n",
    "perturb_types = [\"contentwords\", \"nouns\", \"verbs\", \"nounsverbs\", \"nounsverbsadj\", \"functionwords\"]\n",
    "\n",
    "for perturb in perturb_types:\n",
    "    perturb_df = get_dataset(stimuli_df, original_stimuli, perturb_type=perturb)\n",
    "    print(f\"Created dataset for perturbation type: {perturb}\")\n",
    "perturb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create random noun replacement condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>stimulus_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>story</th>\n",
       "      <th>passage_index</th>\n",
       "      <th>passage_label</th>\n",
       "      <th>passage_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>goods classes.</td>\n",
       "      <td>0</td>\n",
       "      <td>243sentences.0</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we i history owl stylist.</td>\n",
       "      <td>1</td>\n",
       "      <td>243sentences.1</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evening mammals pipe people its part.</td>\n",
       "      <td>2</td>\n",
       "      <td>243sentences.2</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i conditions horns bears coconuts firearms.</td>\n",
       "      <td>3</td>\n",
       "      <td>243sentences.3</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cycles infantry music bow lizards water night.</td>\n",
       "      <td>4</td>\n",
       "      <td>243sentences.4</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>2</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>smell interpretation ingredients.</td>\n",
       "      <td>379</td>\n",
       "      <td>384sentences.379</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.building_part</td>\n",
       "      <td>95</td>\n",
       "      <td>Window</td>\n",
       "      <td>building_part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>storm repair.</td>\n",
       "      <td>380</td>\n",
       "      <td>384sentences.380</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>clothing desk.</td>\n",
       "      <td>381</td>\n",
       "      <td>384sentences.381</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>cultures smell.</td>\n",
       "      <td>382</td>\n",
       "      <td>384sentences.382</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>risk countries routes.</td>\n",
       "      <td>383</td>\n",
       "      <td>384sentences.383</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence  sentence_num  \\\n",
       "0                                    goods classes.             0   \n",
       "1                         we i history owl stylist.             1   \n",
       "2             evening mammals pipe people its part.             2   \n",
       "3       i conditions horns bears coconuts firearms.             3   \n",
       "4    cycles infantry music bow lizards water night.             4   \n",
       "..                                              ...           ...   \n",
       "622               smell interpretation ingredients.           379   \n",
       "623                                   storm repair.           380   \n",
       "624                                  clothing desk.           381   \n",
       "625                                 cultures smell.           382   \n",
       "626                          risk countries routes.           383   \n",
       "\n",
       "          stimulus_id    experiment                       story  \\\n",
       "0      243sentences.0  243sentences     243sentences.beekeeping   \n",
       "1      243sentences.1  243sentences     243sentences.beekeeping   \n",
       "2      243sentences.2  243sentences     243sentences.beekeeping   \n",
       "3      243sentences.3  243sentences     243sentences.beekeeping   \n",
       "4      243sentences.4  243sentences     243sentences.beekeeping   \n",
       "..                ...           ...                         ...   \n",
       "622  384sentences.379  384sentences  384sentences.building_part   \n",
       "623  384sentences.380  384sentences          384sentences.human   \n",
       "624  384sentences.381  384sentences          384sentences.human   \n",
       "625  384sentences.382  384sentences          384sentences.human   \n",
       "626  384sentences.383  384sentences          384sentences.human   \n",
       "\n",
       "     passage_index passage_label passage_category  \n",
       "0                1    beekeeping       beekeeping  \n",
       "1                1    beekeeping       beekeeping  \n",
       "2                1    beekeeping       beekeeping  \n",
       "3                1    beekeeping       beekeeping  \n",
       "4                2    beekeeping       beekeeping  \n",
       "..             ...           ...              ...  \n",
       "622             95        Window    building_part  \n",
       "623             96         Woman            human  \n",
       "624             96         Woman            human  \n",
       "625             96         Woman            human  \n",
       "626             96         Woman            human  \n",
       "\n",
       "[627 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_noun_dataset(sentences):\n",
    "    \"\"\"\n",
    "    Input: list of original sentences\n",
    "    Output: perturbed version of each sentence with only nouns (same number as in original sentence),\n",
    "    but randomly drawn from dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    #set random seed for reproducability\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    \n",
    "    n = ['NOUN', 'PROPN', 'PRON'] #same as in O'Connor & Andreas (2021)\n",
    "    pos_list = n\n",
    "    \n",
    "    #gather all nouns in a list\n",
    "    all_nouns = []\n",
    "    #count how many nouns should go in each sentence\n",
    "    nr_nouns_in_sentences = []\n",
    "    #keep track of which nouns were in which sentence for checking later\n",
    "    nouns_in_sentences = []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        tokens = nlp(sent)\n",
    "        curr_nouns = [str(elm).lower() for elm in tokens if elm.pos_ in pos_list]\n",
    "        \n",
    "        all_nouns += curr_nouns\n",
    "        nr_nouns_in_sentences.append(len(curr_nouns))\n",
    "        nouns_in_sentences.append(curr_nouns)\n",
    "    \n",
    "    perturbed_sentences = []\n",
    "    for ind, n in enumerate(nr_nouns_in_sentences):\n",
    "        random_nouns = random.sample(all_nouns, n)\n",
    "        assert set(random_nouns) != set(nouns_in_sentences[ind]) #check that not the same nouns are selected\n",
    "        perturbed_sentences.append(' '.join(random_nouns) + \".\")\n",
    "        [all_nouns.remove(elm) for elm in random_nouns] #remove selected nouns from list\n",
    "        #print(len(all_nouns))\n",
    "    \n",
    "    assert len(all_words) == 1, f\"Not all words from the dataset have been used. Length of word list is {len(all_words)}!\"\n",
    "     \n",
    "    return perturbed_sentences\n",
    "\n",
    "random_nouns = get_random_noun_dataset(original_stimuli)\n",
    "\n",
    "perturbed_df = stimuli_df.copy()\n",
    "perturbed_df[\"sentence\"] = random_nouns\n",
    "\n",
    "fname = f\"{savedir}/stimuli_randomnouns_noreplacement.pkl\"\n",
    "with open(fname, 'wb') as fout:\n",
    "    pickle.dump(perturbed_df, fout)\n",
    "perturbed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#check that nouns and random nouns datasets have same length strings:\n",
    "with open(os.path.join(savedir,'stimuli_randomnouns_noreplacement.pkl'), \"rb\") as f:\n",
    "    check_randomnouns_df = pickle.load(f)\n",
    "with open(os.path.join(savedir,'stimuli_nouns.pkl'), \"rb\") as f:\n",
    "    check_nouns_df = pickle.load(f)\n",
    "    \n",
    "sent_len_randomnouns = [len(elm.split()) for elm in list(check_randomnouns_df[\"sentence\"])]\n",
    "sent_len_nouns = [len(elm.split()) for elm in list(check_nouns_df[\"sentence\"])]\n",
    "\n",
    "assert sent_len_randomnouns == sent_len_nouns\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
