{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import datetime \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import xarray as xr\n",
    "from importlib import reload \n",
    "import torch\n",
    "from transformers import *\n",
    "from neural_nlp.benchmarks.neural import *\n",
    "from neural_nlp.models import *\n",
    "import neural_nlp\n",
    "from neural_nlp.models.implementations import *\n",
    "from neural_nlp.stimuli import StimulusSet\n",
    "from pathlib import Path\n",
    "import os\n",
    "# Plot specifications\n",
    "sns.set(context='talk')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "plt.rc('axes', edgecolor='black')\n",
    "plt.rc('axes', edgecolor='black')\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "\n",
    "subjectID = '018'\n",
    "subjectIDs = ['018', '288', '289', '296', '426']\n",
    "score_name = '/om/user/msch/share/neural_nlp/benchmark=Pereira2018-encoding,model=gpt2-xl,subsample=None.pkl'\n",
    "# score_name = '/om/user/msch/share/neural_nlp/benchmark=Pereira2018-encoding,model=glove,subsample=None.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import func as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_activations(stimuli, group, layers, tokenizer, model, max_num_words=512):\n",
    "    states_sentences = [[]]*len(layers)\n",
    "    for value in stimuli[group].unique():\n",
    "        df = stimuli[stimuli[group] == value]\n",
    "        sentences = list(df.sentence)\n",
    "        tokenized_sentences = [] # store tokenized stimuli (concatenated in a single list)\n",
    "        indices = [] # keep track of where each sentence ends\n",
    "        for sent in sentences:\n",
    "            tokenized_sentences.extend(tokenizer(sent)['input_ids'])\n",
    "            indices.append(len(tokenized_sentences)-1)\n",
    "        for i in indices: # for each sentence\n",
    "            end = i+1\n",
    "            start = max(0, end - max_num_words) # use all context before it unless it is above max_num_words\n",
    "            input_ids = torch.tensor(tokenized_sentences[start:end])\n",
    "            result_model = model(input_ids, output_hidden_states=True)\n",
    "            hidden_states = result_model[2]\n",
    "            for i, layer in enumerate(layers):\n",
    "                state = hidden_states[layer][-1,:].detach().numpy() # get last word\n",
    "                states_sentences[i].append(state)\n",
    "    return np.array(states_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_pool = [\n",
    "    # primary benchmarks\n",
    "    ('Pereira2018-encoding', PereiraEncoding),\n",
    "    ('Fedorenko2016v3-encoding', Fedorenko2016V3Encoding),\n",
    "    ('Blank2014fROI-encoding', Blank2014fROIEncoding),\n",
    "    # secondary benchmarks\n",
    "    ('Pereira2018-rdm', PereiraRDM),\n",
    "    ('Fedorenko2016v3-rdm', Fedorenko2016V3RDM),\n",
    "    ('Fedorenko2016v3nonlang-encoding', Fedorenko2016V3NonLangEncoding),\n",
    "    ('Blank2014fROI-rdm', Blank2014fROIRDM),\n",
    "]\n",
    "benchmark_pool = {identifier: LazyLoad(lambda identifier=identifier, ctr=ctr: ctr(identifier=identifier))\n",
    "                  for identifier, ctr in benchmark_pool}\n",
    "\n",
    "# how to fetch stimulus set\n",
    "benchmark_test = benchmark_pool['Pereira2018-encoding']\n",
    "stimuli = benchmark_test._target_assembly.attrs['stimulus_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_set = stimuli.copy()\n",
    "stimulus_set.loc[:, 'passage_id'] = stimulus_set['experiment'] + stimulus_set['passage_index'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>stimulus_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>story</th>\n",
       "      <th>passage_index</th>\n",
       "      <th>passage_label</th>\n",
       "      <th>passage_category</th>\n",
       "      <th>passage_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beekeeping encourages the conservation of loca...</td>\n",
       "      <td>0</td>\n",
       "      <td>243sentences.0</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>243sentences1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is in every beekeeper's interest to conserv...</td>\n",
       "      <td>1</td>\n",
       "      <td>243sentences.1</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>243sentences1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a passive form of agriculture, it does not ...</td>\n",
       "      <td>2</td>\n",
       "      <td>243sentences.2</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>243sentences1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beekeepers also discourage the use of pesticid...</td>\n",
       "      <td>3</td>\n",
       "      <td>243sentences.3</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>1</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>243sentences1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artisanal beekeepers go to extremes for their ...</td>\n",
       "      <td>4</td>\n",
       "      <td>243sentences.4</td>\n",
       "      <td>243sentences</td>\n",
       "      <td>243sentences.beekeeping</td>\n",
       "      <td>2</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>beekeeping</td>\n",
       "      <td>243sentences2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Some windows have multiple panes to increase i...</td>\n",
       "      <td>379</td>\n",
       "      <td>384sentences.379</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.building_part</td>\n",
       "      <td>95</td>\n",
       "      <td>Window</td>\n",
       "      <td>building_part</td>\n",
       "      <td>384sentences95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>A woman is a female human adult.</td>\n",
       "      <td>380</td>\n",
       "      <td>384sentences.380</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "      <td>384sentences96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>A woman is stereotypically seen as a caregiver.</td>\n",
       "      <td>381</td>\n",
       "      <td>384sentences.381</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "      <td>384sentences96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>A woman can become pregnant and bear children.</td>\n",
       "      <td>382</td>\n",
       "      <td>384sentences.382</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "      <td>384sentences96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>A woman has different reproductive organs than...</td>\n",
       "      <td>383</td>\n",
       "      <td>384sentences.383</td>\n",
       "      <td>384sentences</td>\n",
       "      <td>384sentences.human</td>\n",
       "      <td>96</td>\n",
       "      <td>Woman</td>\n",
       "      <td>human</td>\n",
       "      <td>384sentences96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  sentence_num  \\\n",
       "0    Beekeeping encourages the conservation of loca...             0   \n",
       "1    It is in every beekeeper's interest to conserv...             1   \n",
       "2    As a passive form of agriculture, it does not ...             2   \n",
       "3    Beekeepers also discourage the use of pesticid...             3   \n",
       "4    Artisanal beekeepers go to extremes for their ...             4   \n",
       "..                                                 ...           ...   \n",
       "622  Some windows have multiple panes to increase i...           379   \n",
       "623                   A woman is a female human adult.           380   \n",
       "624    A woman is stereotypically seen as a caregiver.           381   \n",
       "625     A woman can become pregnant and bear children.           382   \n",
       "626  A woman has different reproductive organs than...           383   \n",
       "\n",
       "          stimulus_id    experiment                       story  \\\n",
       "0      243sentences.0  243sentences     243sentences.beekeeping   \n",
       "1      243sentences.1  243sentences     243sentences.beekeeping   \n",
       "2      243sentences.2  243sentences     243sentences.beekeeping   \n",
       "3      243sentences.3  243sentences     243sentences.beekeeping   \n",
       "4      243sentences.4  243sentences     243sentences.beekeeping   \n",
       "..                ...           ...                         ...   \n",
       "622  384sentences.379  384sentences  384sentences.building_part   \n",
       "623  384sentences.380  384sentences          384sentences.human   \n",
       "624  384sentences.381  384sentences          384sentences.human   \n",
       "625  384sentences.382  384sentences          384sentences.human   \n",
       "626  384sentences.383  384sentences          384sentences.human   \n",
       "\n",
       "     passage_index passage_label passage_category      passage_id  \n",
       "0                1    beekeeping       beekeeping   243sentences1  \n",
       "1                1    beekeeping       beekeeping   243sentences1  \n",
       "2                1    beekeeping       beekeeping   243sentences1  \n",
       "3                1    beekeeping       beekeeping   243sentences1  \n",
       "4                2    beekeeping       beekeeping   243sentences2  \n",
       "..             ...           ...              ...             ...  \n",
       "622             95        Window    building_part  384sentences95  \n",
       "623             96         Woman            human  384sentences96  \n",
       "624             96         Woman            human  384sentences96  \n",
       "625             96         Woman            human  384sentences96  \n",
       "626             96         Woman            human  384sentences96  \n",
       "\n",
       "[627 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimulus_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check number of overlapping last words\n",
    "stim = pd.read_csv('/Users/gt/Documents/GitHub/control-neural/data/pereira_stimulus_set.csv')\n",
    "last_words = [x.split(' ')[-1].lower() for x in stim.sentence.values]\n",
    "np.unique(last_words, return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = 'gpt2'\n",
    "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(pretrained_weights)\n",
    "model_gpt2 = GPT2Model.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t6 = get_model_activations(stimulus_set, 'passage_id', [6], tokenizer_gpt2, model_gpt2, max_num_words=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 627, 768)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = get_model_activations(stimulus_set, 'passage_id', [7], tokenizer_gpt2, model_gpt2, max_num_words=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t6=np.squeeze(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "t7=np.squeeze(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t12 = np.squeeze(get_model_activations(stimulus_set, 'passage_id', [12], tokenizer_gpt2, model_gpt2, max_num_words=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('GPT2_layer12_act_Pereira2018.npy', t12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir((Path(os.path.dirname(os.getcwd())) / '..' / '..'/ 'CKA-Centered-Kernel-Alignment').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gt/Documents/GitHub/CKA-Centered-Kernel-Alignment'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import cca_core\n",
    "from CKA import linear_CKA, kernel_CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 768)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrt = np.corrcoef(t6, t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1254, 1254)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(corrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.92892599, 0.89543713, ..., 0.85815811, 0.83035886,\n",
       "        0.78656707],\n",
       "       [0.92892599, 1.        , 0.92689966, ..., 0.87903157, 0.86623215,\n",
       "        0.83279897],\n",
       "       [0.89543713, 0.92689966, 1.        , ..., 0.87513774, 0.87777565,\n",
       "        0.85968498],\n",
       "       ...,\n",
       "       [0.85815811, 0.87903157, 0.87513774, ..., 1.        , 0.93713077,\n",
       "        0.91197734],\n",
       "       [0.83035886, 0.86623215, 0.87777565, ..., 0.93713077, 1.        ,\n",
       "        0.93501629],\n",
       "       [0.78656707, 0.83279897, 0.85968498, ..., 0.91197734, 0.93501629,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CKA, between X and Y: 0.9568201562019218\n",
      "Linear CKA, between X and X: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Linear CKA, between X and Y: {}'.format(linear_CKA(t6.T,t7.T)))\n",
    "print('Linear CKA, between X and X: {}'.format(linear_CKA(t6.T,t6.T)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Kernel CKA, between X and Y: 1.0000000000000002\n",
      "RBF Kernel CKA, between X and X: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print('RBF Kernel CKA, between X and Y: {}'.format(kernel_CKA(t6, t7)))\n",
    "print('RBF Kernel CKA, between X and X: {}'.format(kernel_CKA(t7, t7)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008682458764857041"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_CKA(t6.T,t12.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008682458764857041"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_CKA(t7.T,t12.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}